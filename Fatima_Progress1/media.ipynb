{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBnVSx25qGDX",
        "outputId": "2cde4740-9f39-43e1-a857-2e71bfe72d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Downloading mediapipe-0.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: protobuf, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.15 protobuf-4.25.5 sounddevice-0.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install mediapipe opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0AxuAA5qG_H",
        "outputId": "0a0e40db-dc06-4c0a-b008-efd841183514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model to /usr/local/lib/python3.10/dist-packages/mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "# Initialize MediaPipe Holistic model\n",
        "mp_holistic = mp.solutions.holistic\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# Load the video file\n",
        "video_path = 'angry.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_count = 0  # Frame counter\n",
        "frame_skip = 5   # Process every 5th frame\n",
        "\n",
        "# Initialize holistic model\n",
        "with mp_holistic.Holistic(static_image_mode=False, model_complexity=2) as holistic:\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Only process every 5th frame\n",
        "        if frame_count % frame_skip == 0:\n",
        "            # Convert the image to RGB as mediapipe expects it\n",
        "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Process the image and detect landmarks\n",
        "            results = holistic.process(image)\n",
        "\n",
        "            # Convert the image back to BGR for rendering\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            # Draw the landmarks on the image (optional, for visualization)\n",
        "            if results.pose_landmarks:\n",
        "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
        "            if results.face_landmarks:\n",
        "                mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS)\n",
        "            if results.left_hand_landmarks:\n",
        "                mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "            if results.right_hand_landmarks:\n",
        "                mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "\n",
        "            # Display the image (optional, for real-time visualization)\n",
        "            from google.colab.patches import cv2_imshow\n",
        "            cv2_imshow(image)\n",
        "\n",
        "            # Extract landmarks (data points)\n",
        "            if results.pose_landmarks:\n",
        "                print(\"Pose landmarks:\")\n",
        "                for id, lm in enumerate(results.pose_landmarks.landmark):\n",
        "                    print(f\"ID: {id}, X: {lm.x}, Y: {lm.y}, Z: {lm.z}, Visibility: {lm.visibility}\")\n",
        "\n",
        "            if results.face_landmarks:\n",
        "                print(\"Face landmarks:\")\n",
        "                for id, lm in enumerate(results.face_landmarks.landmark):\n",
        "                    print(f\"ID: {id}, X: {lm.x}, Y: {lm.y}, Z: {lm.z}\")\n",
        "\n",
        "            if results.left_hand_landmarks:\n",
        "                print(\"Left hand landmarks:\")\n",
        "                for id, lm in enumerate(results.left_hand_landmarks.landmark):\n",
        "                    print(f\"ID: {id}, X: {lm.x}, Y: {lm.y}, Z: {lm.z}\")\n",
        "\n",
        "            if results.right_hand_landmarks:\n",
        "                print(\"Right hand landmarks:\")\n",
        "                for id, lm in enumerate(results.right_hand_landmarks.landmark):\n",
        "                    print(f\"ID: {id}, X: {lm.x}, Y: {lm.y}, Z: {lm.z}\")\n",
        "\n",
        "        # Increment the frame counter\n",
        "        frame_count += 1\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "# Release the video capture and close windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# Initialize MediaPipe Holistic model\n",
        "mp_holistic = mp.solutions.holistic\n",
        "holistic = mp_holistic.Holistic(static_image_mode=False)\n",
        "\n",
        "# Capture webcam input\n",
        "cap = cv2.VideoCapture(0)\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "fps = 10\n",
        "duration = 5  # seconds\n",
        "frame_count = fps * duration\n",
        "\n",
        "frames = []\n",
        "landmarks_data = []\n",
        "\n",
        "# Start recording for 5 seconds\n",
        "print(\"Recording started...\")\n",
        "start_time = time.time()\n",
        "while len(frames) < frame_count:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Failed to capture frame.\")\n",
        "        break\n",
        "\n",
        "    frames.append(frame)\n",
        "\n",
        "    # Convert BGR image to RGB for processing\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process with holistic model\n",
        "    results = holistic.process(rgb_frame)\n",
        "\n",
        "    # Save pose, face, and hand landmarks\n",
        "    pose_landmarks = results.pose_landmarks\n",
        "    face_landmarks = results.face_landmarks\n",
        "    left_hand_landmarks = results.left_hand_landmarks\n",
        "    right_hand_landmarks = results.right_hand_landmarks\n",
        "\n",
        "    # Prepare vectors\n",
        "    frame_landmarks = {}\n",
        "\n",
        "    if pose_landmarks:\n",
        "        frame_landmarks['pose'] = np.array([[lm.x, lm.y, lm.z] for lm in pose_landmarks.landmark])\n",
        "\n",
        "    if face_landmarks:\n",
        "        frame_landmarks['face'] = np.array([[lm.x, lm.y, lm.z] for lm in face_landmarks.landmark])\n",
        "\n",
        "    if left_hand_landmarks:\n",
        "        frame_landmarks['left_hand'] = np.array([[lm.x, lm.y, lm.z] for lm in left_hand_landmarks.landmark])\n",
        "\n",
        "    if right_hand_landmarks:\n",
        "        frame_landmarks['right_hand'] = np.array([[lm.x, lm.y, lm.z] for lm in right_hand_landmarks.landmark])\n",
        "\n",
        "    landmarks_data.append(frame_landmarks)\n",
        "\n",
        "    if time.time() - start_time >= duration:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "print(\"Recording finished.\")\n",
        "\n",
        "# Function to return the data points as vectors\n",
        "def get_landmarks_as_vectors(landmarks_data):\n",
        "    vectors = []\n",
        "    for frame in landmarks_data:\n",
        "        frame_vectors = {}\n",
        "        if 'pose' in frame:\n",
        "            frame_vectors['pose'] = frame['pose']\n",
        "        if 'face' in frame:\n",
        "            frame_vectors['face'] = frame['face']\n",
        "        if 'left_hand' in frame:\n",
        "            frame_vectors['left_hand'] = frame['left_hand']\n",
        "        if 'right_hand' in frame:\n",
        "            frame_vectors['right_hand'] = frame['right_hand']\n",
        "\n",
        "        vectors.append(frame_vectors)\n",
        "    return vectors\n",
        "\n",
        "# Get the landmarks as vectors\n",
        "landmarks_vectors = get_landmarks_as_vectors(landmarks_data)\n",
        "\n",
        "# Output the vectors for each frame\n",
        "for i, vectors in enumerate(landmarks_vectors):\n",
        "    print(f\"Frame {i+1}:\")\n",
        "    for landmark_type, coords in vectors.items():\n",
        "        print(f\"  {landmark_type}: {coords}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcJdr_musvKX",
        "outputId": "20e47859-066f-48c3-c9e4-3af7538031d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recording started...\n",
            "Failed to capture frame.\n",
            "Recording finished.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}